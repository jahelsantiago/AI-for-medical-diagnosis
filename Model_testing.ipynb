{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model testing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTOet4rPFUtJJTViOoPqai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahelsantiago/AI-for-medical-diagnosis/blob/main/Model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpDH5y6Pa8kz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "import random\n",
        "import cv2\n",
        "from keras.preprocessing import image\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from tensorflow.compat.v1.logging import INFO, set_verbosity"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Z0CRU3AF7Q"
      },
      "source": [
        "def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n",
        "\n",
        "    def weighted_loss(y_true, y_pred):\n",
        "     \n",
        "        loss = 0.0\n",
        "                \n",
        "\n",
        "        for i in range(len(pos_weights)):\n",
        "            # for each class, add average weighted loss for that class \n",
        "            loss += -1 * K.mean((pos_weights[i] * y_true[:, i] * K.log(y_pred[:, i] + epsilon) + \n",
        "                     neg_weights[i] * (1 - y_true[:, i]) * K.log(1 - y_pred[:, i] + epsilon)))\n",
        "        return loss\n",
        "            \n",
        "    return weighted_loss\n",
        "\n",
        "def grad_cam(input_model, image, cls, layer_name, H=320, W=320):\n",
        "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
        "    y_c = input_model.output[0, cls]\n",
        "    conv_output = input_model.get_layer(layer_name).output\n",
        "    grads = K.gradients(y_c, conv_output)[0]\n",
        "\n",
        "    gradient_function = K.function([input_model.input], [conv_output, grads])\n",
        "\n",
        "    output, grads_val = gradient_function([image])\n",
        "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
        "\n",
        "    weights = np.mean(grads_val, axis=(0, 1))\n",
        "    cam = np.dot(output, weights)\n",
        "\n",
        "    # Process CAM\n",
        "    cam = cv2.resize(cam, (W, H), cv2.INTER_LINEAR)\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cam / cam.max()\n",
        "    return cam\n",
        "\n",
        "\n",
        "def compute_gradcam(model, img, image_dir, df, labels, selected_labels,\n",
        "                    layer_name='bn'):\n",
        "    preprocessed_input = load_image(img, image_dir, df)\n",
        "    predictions = model.predict(preprocessed_input)\n",
        "\n",
        "    print(\"Loading original image\")\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.subplot(151)\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "    plt.imshow(load_image(img, image_dir, df, preprocess=False), cmap='gray')\n",
        "\n",
        "    j = 1\n",
        "    for i in range(len(labels)):\n",
        "        if labels[i] in selected_labels:\n",
        "            print(f\"Generating gradcam for class {labels[i]}\")\n",
        "            gradcam = grad_cam(model, preprocessed_input, i, layer_name)\n",
        "            plt.subplot(151 + j)\n",
        "            plt.title(f\"{labels[i]}: p={predictions[0][i]:.3f}\")\n",
        "            plt.axis('off')\n",
        "            plt.imshow(load_image(img, image_dir, df, preprocess=False),\n",
        "                       cmap='gray')\n",
        "            plt.imshow(gradcam, cmap='jet', alpha=min(0.5, predictions[0][i]))\n",
        "            j += 1\n",
        "\n",
        "def load_image(img, image_dir, df, preprocess=True, H=320, W=320):\n",
        "    \"\"\"Load and preprocess image.\"\"\"\n",
        "    img_path = image_dir + img\n",
        "    mean, std = get_mean_std_per_batch(img_path, df, H=H, W=W)\n",
        "    x = image.load_img(img_path, target_size=(H, W))\n",
        "    if preprocess:\n",
        "        x -= mean\n",
        "        x /= std\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "    return x\n",
        "\n",
        "\n",
        "  def get_mean_std_per_batch(image_path, df, H=320, W=320):\n",
        "    sample_data = []\n",
        "    for idx, img in enumerate(df.sample(100)[\"Image\"].values):\n",
        "        # path = image_dir + img\n",
        "        sample_data.append(\n",
        "            np.array(image.load_img(image_path, target_size=(H, W))))\n",
        "\n",
        "    mean = np.mean(sample_data[0])\n",
        "    std = np.std(sample_data[0])\n",
        "    return mean, std"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzu6Pd7obqbx"
      },
      "source": [
        "# create the base pre-trained model\n",
        "base_model = DenseNet121(weights=None, include_top=False)\n",
        "\n",
        "x = base_model.output\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# and a logistic layer\n",
        "predictions = Dense(14, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "#model.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights))\n",
        "model.load_weights(\"/tmp/pretrained_model.h5\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mPz_piDhiwS"
      },
      "source": [
        "preprocessed_input = load_image(img, image_dir, df)\n",
        "predictions = model.predict(preprocessed_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}